{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;\f1\fmodern\fcharset0 Courier-Bold;\f2\froman\fcharset0 Times-Roman;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue233;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c93333;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).\
All Data shape:  (59761, 9297)\
Label shape:  (59761,)\
Image data shape:  (59761, 9296)\
(38844, 9296)\
(18825, 9296)\
Model: "sequential_10"\
_________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
flatten_10 (Flatten)         (None, 9296)              0         \
_________________________________________________________________\
dense_27 (Dense)             (None, 100)               929700    \
_________________________________________________________________\
dense_28 (Dense)             (None, 30)                3030      \
_________________________________________________________________\
dense_29 (Dense)             (None, 10)                310       \
=================================================================\
Total params: 933,040\
Trainable params: 933,040\
Non-trainable params: 0\
_________________________________________________________________\
Model Summery:  None\
Model Layers:  [<keras.layers.core.Flatten object at 0x7ff749142710>, <keras.layers.core.Dense object at 0x7ff74916ef50>, <keras.layers.core.Dense object at 0x7ff747334e90>, <keras.layers.core.Dense object at 0x7ff74be9df50>]\
Weights:  [[-0.0161059  -0.01528926 -0.01215145 ...  0.00554078 -0.01937965\
  -0.00362044]\
 [-0.02131343  0.00526851 -0.02372885 ...  0.00979547 -0.01024834\
  -0.00631937]\
 [ 0.01061398  0.00275067  0.00830919 ...  0.00411151  0.02199405\
   0.01428214]\
 ...\
 [ 0.00354441 -0.0140327  -0.01268585 ...  0.01622613 -0.0133026\
  -0.02501968]\
 [-0.01023991 -0.00180313  0.0100148  ... -0.002448   -0.0030278\
   0.01956215]\
 [ 0.0116287   0.00178779 -0.00120654 ...  0.01459697 -0.0032195\
   0.02381489]]\
Biases Shape:  (100,)\
Epoch 1/30\
304/304 [==============================] - 8s 25ms/step - loss: 6867413735033395765487918383104.0000 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1006\
Epoch 2/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1006\
Epoch 3/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.0983\
Epoch 4/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0985\
Epoch 5/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.0985\
Epoch 6/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.0985\
Epoch 7/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.0985\
Epoch 8/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 9/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 10/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 11/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 12/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 13/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 14/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 15/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 16/30\
304/304 [==============================] - 8s 27ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 17/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 18/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 19/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 20/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 21/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 22/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 23/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 24/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 25/30\
304/304 [==============================] - 9s 29ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 26/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 27/30\
304/304 [==============================] - 8s 25ms/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 28/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 29/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.0985\
Epoch 30/30\
304/304 [==============================] - 8s 26ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0985\
fit history:  <keras.callbacks.History object at 0x7ff74bf367d0>\
66/66 [==============================] - 0s 5ms/step - loss: 2.3027 - accuracy: 0.0970\
Classification Report: \
---------------------------------------------------------------------------\
ValueError                                Traceback (most recent call last)\
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://localhost:8080/#"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 <ipython-input-12-397da92191eb>}} in <module>()\
\pard\pardeftab720\partightenfactor0

\f1\b \cf2      69
\f0\b0  predition = model_seq.predict(X_val)\

\f1\b      70
\f0\b0  print("Classification Report: ")\
---> 71 print(classification_report(y_val, predition))\

\f1\b      72
\f0\b0  print("Confussion Matrix: ")\

\f1\b      73
\f0\b0  print(confusion_matrix(y_val,predition))\
\
\pard\pardeftab720\sa120\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0
\cf2 1 frames\
\pard\pardeftab720\sa120\partightenfactor0
\cf2 \
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://localhost:8080/#"}}{\fldrslt 
\f0 \cf3 \ul \ulc3 \strokec3 /usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py}}
\f0  in _check_targets(y_true, y_pred)\
\pard\pardeftab720\partightenfactor0

\f1\b \cf2      88
\f0\b0      if len(y_type) > 1:\

\f1\b      89
\f0\b0          raise ValueError("Classification metrics can't handle a mix of \{0\} "\
---> 90                          "and \{1\} targets".format(type_true, type_pred))\

\f1\b      91
\f0\b0  \

\f1\b      92
\f0\b0      # We can't have more than one value on y_type => The set is no more needed\
\
ValueError: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets\
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
{{\NeXTGraphic unknown.png \width9660 \height6140 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\
}