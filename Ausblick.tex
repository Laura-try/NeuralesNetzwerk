\section{Ausblick} \label{Kapitel: Ausblick}
Während der Arbeit und Auswertung der Ergebnisse sind mehrere Ideen zur Fortsetzung  und Verbesserung des Projektes entstanden.\\
Eine wichtige Voraussetzung, um den Teststand mit Maschinellem Lernen zu benutzten, wäre alle acht Ziffern zu erkennen.  Dazu gäbe es zwei Methoden: entweder alle Ziffern mit einem ML-Algorithmus zu behandeln oder die Ziffern mit einer Methode zu trennen und einzeln in das, in dieser Arbeit,  entwickelte Modell einzupflegen.\\
Alle Ziffern mit einem Maschinellen Lernen-Modell zu erfassen, wäre extrem aufwendig und datenintensiv.  Unter der Annahme, dass mindestens 1.000 verschiedene Aufnahmen von der gleichen Darstellung gemacht werden müssten, und es bei acht Positionen mit je zehn verschiedene Ziffern $10^{8}= 100.000.000$ Darstellung gibt, sind das 100 Milliarden  Aufnahmen.  Bei einer Aufnahmegeschwindigkeit von 22 $\mu$s sind das 25 Tage und dabei wurde noch nicht eingerechnet, dass Zeit gebraucht wird, um die Einstellungen zu ändern. Der reine Zeitfaktor macht diesen Ansatz nicht realistisch. Zusätzlich käme noch die Datenmenge hinzu.  Der npy-File für dieses Projekt mit seinen 60.000 Aufnahmen im skalierten Zustand ist schon 3,5 GB groß.  Wenn man von einem linearen Faktor bei der Datengröße aus geht, wären das 6.000 GB bei den skalierten Aufnahmen einer Ziffer.\\
Die zweite Variante wäre, aus den Aufnahmen die Ziffern zu trennen. Dazu gibt es unterschiedliche Methoden. In der Literatur wird oft ein MSER-Ansatz benutzt.  Ein MSER ist ein Algorithmus mit dem Region und Kanten in Aufnahmen erkannt werden.
Die andere Methode die Ziffern von einander zu trennen, würde auf dem bekannten Layout der Anzeige beruhen.  Hierzu würden die Eck-LEDs erkannt werden und mit ihnen die Aufnahme in acht Rechtecke für die einzelnen Ziffern unterteilt werden. Diese Ausschnitte könnten dann mit dem Maschinellen Lernen-Modell erkannt werden.\\
Diese Vorgehensweise sollte ohne großen Aufwand zu implementieren sein.  Die größte Schwierigkeit dabei wäre,  dass DaVis auf C++ basiert und keine Bibliothek für Maschinellen Lernen besitzt. Die von DaVis aufgenommen Bilder müssten also in Python mit dem ML-Modell erkannt werden oder es müsste die TensorFlow Bibliothek in DaVis eingebaut werden.

\subsection{DaVis}
Beim Arbeiten an dem Maschinellen Lernen-Projekt sind mehrere Dinge aufgefallen,  die in DaVis implementiert werden könnten,  um die Möglichkeit zu schaffen Maschinelle Lernen-Projekt direkt in DaVis auszuführen.
Als erstes wäre es sinnvoll,  Aufnahmen mit Labeln versehen zu können. DaVis besitzt viele Möglichkeiten,  Aufnahmen zu bearbeiten und zu analysieren (z.B.  Teilstücke ausschneiden und Histogramm der Helligkeitswerte).
Es gibt in der Software schon die Option,  Attribute zu den Aufnahmen hinzufügen und manche Information, wie Aufnahmezeit wird schon automatisch mit gespeichert.  Ein Attribute zum Speichern des Labels wäre also ein geringer Aufwand.  Vernünftig wäre die Zuordnungsmöglichkeit des Labels in alle aufgenommen Bilder einer Reihe, einzeln pro Bild oder in einer Schleifen-Funktion, so wie es für diese Arbeit benötigt wurde.\\
Weitere Überlegung müssten dazu angestellt werden,  wie man das Maschinelle Lernen-Model mit DaVis verknüpft. Dazu gibt es drei Möglichkeiten:\\
Erstens die Aufnahmen werden nur in DaVis erstellt und bearbeitet und dann mit der lvreader-Bibliothek  in Python eingelesen. In einem Python-Script also außerhalb von DaVis wird das Modell erstellt und mit dem Model gearbeitet. Nachdem das Modell trainiert und gesichert wurde, müssen alle Aufnahmen, die von dem Modell bewertet werden sollen,  in Python geladen werden. Dieses ist recht aufwendig für den Anwender ist aber mit dem aktuellen Stand von DaVis schon möglich. \\
Die zweite Möglichkeit wäre die Modelle immer noch in Python erstellen zu lassen, aber in DaVis eine Methode zu implementieren, um die Modelle zu laden und mit ihnen Aufnahmen zu analysieren.  Dazu müsste die in Python geschriebenen Maschinelles Lernen-Modelle in der passenden Maschinellen Lernen-Bibliothek programmiert sein.  Dazu bieten sich zum Beispiel die Bibliothek  Pytorch \cite{pytorch} oder TensorFlow an. Beide besitzen sowohl Bibliotheken in C++ als auch in Python und haben die Möglichkeit,  Modelle aus Python in C++ zu laden \cite{pytorch} \cite{tensorflowC}. \\
Die dritte Möglichkeit wäre in DaVis ein Option zu implementieren, um ein Maschinelles Lernen-Modell direkt in DaVis zu bauen.  Hierzu wäre es sinnvoll eine Maschinelle Lernen-Bibliothek in DaVis zu integrieren.  Dann auf dieser Bibliothek beruhend eine Oberfläche zur Modell-Entwicklung in DaVis einzubetten.  Geeignet wäre dazu sowohl TensorFlow als auch Pytorch (Torch als C++ Bibliothek) \cite{Kolodiazhnyi2020}.